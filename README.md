# Learning Commonality and Specificity via Feature Decoupling for Cross-View Geo-Localization
Cross-View Geo-Localization
Cross-View Geo-Localization aims to address the problem of image localization in GNSS-denied environments, remaining a highly challenging task. Most existing methods focus solely on learning common representations across different views, while neglecting the unique representations specific to each view. We propose Common and Specific Feature Decoupling (CSFD), a simple training heuristic for cross-view geo-localization. CSFD can be easily integrated into existing cross-view geo-localization baselines with minimal additional network parameters, effectively decoupling the common features shared across views from the unique features within each view. This process is achieved through parallel domain alignment and domain separation operations, which constrain the network to learn the \textit{real} commonality under cross-view conditions and thus enhance the generalization ability of localization tasks. We evaluate CSFD on two common cross-view scenarios (street-satellite and UAV-satellite) and demonstrate its consistent improvements under various settings and baselines. Experimental results indicate that our CSFD enhances existing methods, achieving state-of-the-art results on widely used cross-view datasets such as CVACT, VIGOR, University-1652 and SUES-200. For example, CSFD improves the Recall@1 performance of existing methods by an average of 1.58\% and 1.97\% in the same-region and cross-region setups of VIGOR dataset, respectively, which fully demonstrates its excellent universality and generalization capabilities.
